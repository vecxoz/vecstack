{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StackingTransformer (scikit-learn API for stacking)\n",
    "# Regression\n",
    "# 2-level stacking: step-by-step and using Pipeline\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from xgboost import XGBRegressor\n",
    "from vecstack import StackingTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "\n",
    "# Make train/test split\n",
    "# As usual in machine learning task we have X_train, y_train, and X_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize 1st level estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caution! All estimators and parameter values are just \n",
    "# demonstrational and shouldn't be considered as recommended.\n",
    "\n",
    "# This is list of tuples\n",
    "# Each tuple contains arbitrary unique name and estimator object\n",
    "estimators_L1 = [\n",
    "    ('et', ExtraTreesRegressor(random_state=0, n_jobs=-1, \n",
    "                               n_estimators=100, max_depth=3)),\n",
    "        \n",
    "    ('rf', RandomForestRegressor(random_state=0, n_jobs=-1, \n",
    "                                 n_estimators=100, max_depth=3)),\n",
    "        \n",
    "    ('xgb', XGBRegressor(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
    "                         n_estimators=100, max_depth=3))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize StackingTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = StackingTransformer(estimators=estimators_L1,   # base estimators\n",
    "                            regression=True,            # regression task (if you need \n",
    "                                                        #     classification - set to False)\n",
    "                            variant='A',                # oof for train set, predict test \n",
    "                                                        #     set in each fold and find mean\n",
    "                            metric=mean_absolute_error, # metric: callable\n",
    "                            n_folds=4,                  # number of folds\n",
    "                            shuffle=True,               # shuffle the data\n",
    "                            random_state=0,             # ensure reproducibility\n",
    "                            verbose=2)                  # print all info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Step-by-step approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit StackingTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [regression]\n",
      "metric:       [mean_absolute_error]\n",
      "variant:      [A]\n",
      "n_estimators: [3]\n",
      "\n",
      "estimator  0: [et: ExtraTreesRegressor]\n",
      "    fold  0:  [0.65383143]\n",
      "    fold  1:  [0.65059961]\n",
      "    fold  2:  [0.66233582]\n",
      "    fold  3:  [0.64449777]\n",
      "    ----\n",
      "    MEAN:     [0.65281616] + [0.00643746]\n",
      "\n",
      "estimator  1: [rf: RandomForestRegressor]\n",
      "    fold  0:  [0.58416160]\n",
      "    fold  1:  [0.56449564]\n",
      "    fold  2:  [0.57730149]\n",
      "    fold  3:  [0.55014073]\n",
      "    ----\n",
      "    MEAN:     [0.56902487] + [0.01298795]\n",
      "\n",
      "estimator  2: [xgb: XGBRegressor]\n",
      "    fold  0:  [0.37287275]\n",
      "    fold  1:  [0.36827074]\n",
      "    fold  2:  [0.37315715]\n",
      "    fold  3:  [0.36447933]\n",
      "    ----\n",
      "    MEAN:     [0.36969499] + [0.00358177]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stack = stack.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get stacked features: transform (predict) train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [et: ExtraTreesRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [rf: RandomForestRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [xgb: XGBRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "S_train = stack.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [et: ExtraTreesRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [rf: RandomForestRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [xgb: XGBRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "S_test = stack.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the result\n",
    "\n",
    "Let's look at our stacked features.  \n",
    "We have three 1st level estimators, so we expect to get three columns in `S_train` and `S_test`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1381431 , 1.89449961, 1.85192811],\n",
       "       [2.29310757, 1.89309918, 2.92809105],\n",
       "       [2.07256939, 1.89449961, 2.10903692],\n",
       "       [1.51938275, 1.53835871, 1.37909698],\n",
       "       [1.93450337, 2.737813  , 3.23252964]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.12570438, 1.88503507, 1.57685581],\n",
       "       [2.57631542, 2.67168873, 2.70525175],\n",
       "       [2.06940157, 1.88669837, 1.69479051],\n",
       "       [1.64434775, 1.20196782, 0.96695787],\n",
       "       [2.33799194, 2.98206787, 3.8881467 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply 2nd level estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction score: [0.35320658]\n"
     ]
    }
   ],
   "source": [
    "# Initialize 2nd level estimator\n",
    "final_estimator = XGBRegressor(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
    "                               n_estimators=100, max_depth=3)\n",
    "\n",
    "# Fit\n",
    "final_estimator = final_estimator.fit(S_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = final_estimator.predict(S_test)\n",
    "\n",
    "# Final prediction score\n",
    "print('Final prediction score: [%.8f]' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some useful StackingTransformer attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of base estimators\n",
    "# Type: int\n",
    "stack.n_estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65383143, 0.65059961, 0.66233582, 0.64449777],\n",
       "       [0.5841616 , 0.56449564, 0.57730149, 0.55014073],\n",
       "       [0.37287275, 0.36827074, 0.37315715, 0.36447933]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scores for each estimator (rows) in each fold (columns)\n",
    "# Type: 2d numpy array\n",
    "stack.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('et', np.float64(0.6528161581671601), np.float64(0.006437456871932304)),\n",
       " ('rf', np.float64(0.5690248659195717), np.float64(0.012987952596095562)),\n",
       " ('xgb', np.float64(0.3696949910225933), np.float64(0.00358176792828805))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean and std for each estimator\n",
    "# Type: list of tuples\n",
    "stack.mean_std_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.369695</td>\n",
       "      <td>0.003582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.569025</td>\n",
       "      <td>0.012988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>et</td>\n",
       "      <td>0.652816</td>\n",
       "      <td>0.006437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name      mean       std\n",
       "2  xgb  0.369695  0.003582\n",
       "1   rf  0.569025  0.012988\n",
       "0   et  0.652816  0.006437"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean and std convenient representation using pandas.DataFrame\n",
    "df = pd.DataFrame.from_records(stack.mean_std_, columns=['name', 'mean', 'std'])\n",
    "# Sort by column 'mean' (best on the top)\n",
    "df.sort_values('mean', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pipeline\n",
    "\n",
    "StackingTransformer is fully scikit-learn compatible so we can easily implement **arbitrary number of stacking levels** using Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify steps of Pipeline\n",
    "steps = [('stack', stack),\n",
    "         ('final_estimator', final_estimator)]\n",
    "\n",
    "# Init Pipeline\n",
    "pipe = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have several stacking levels our Pipeline steps would be:\n",
    "# steps = [('stack_L1', stack_L1),\n",
    "#          ('stack_L2', stack_L2),\n",
    "#          ('stack_L99', stack_L99),  # :-)\n",
    "#          ('final_estimator', final_estimator)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ability to set parameters of nested estimators and transformers\n",
    "\n",
    "Following scikit-learn naming convention we can access parameters of nested estimators and transformers.  \n",
    "Each nested level (should not be confused with stacking level) is separated by double underscore `__`.  \n",
    "For example using Pipeline we want StackingTransformer to be silent.  \n",
    "We can access StackingTransformer parameter `verbose` through `pipe` instance as `stack__verbose`.  \n",
    "We can also set any parameter of 1st level estimators inside StackingTransformer.  \n",
    "We can access XGBoost parameter `learning_rate` through `pipe` instance as `stack__xgb__learning_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipe.set_params(stack__verbose=0)\n",
    "# pipe = pipe.set_params(stack__xgb__learning_rate=0.555)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit and predict using Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction score using Pipeline: [0.35320658]\n"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "pipe = pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_pipe = pipe.predict(X_test)\n",
    "\n",
    "# Final prediction score\n",
    "print('Final prediction score using Pipeline: [%.8f]' % mean_absolute_error(y_test, y_pred_pipe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ability to save fitted Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Pipeline\n",
    "_ = joblib.dump(pipe, 'pipe_with_stack.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction score using loaded Pipeline: [0.35320658]\n"
     ]
    }
   ],
   "source": [
    "# Load Pipeline\n",
    "pipe_loaded = joblib.load('pipe_with_stack.pkl')\n",
    "\n",
    "# Predict using loaded Pipeline\n",
    "y_pred_pipe_loaded = pipe_loaded.predict(X_test)\n",
    "\n",
    "# Final prediction score\n",
    "print('Final prediction score using loaded Pipeline: [%.8f]' % mean_absolute_error(y_test, y_pred_pipe_loaded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Step-by-step approach is useful when we need direct access to stacked features `S_train` and `S_test`.  \n",
    "Pipeline approach is useful when we need to represent many steps in a single object.  \n",
    "Both approaches give exactly the same score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
